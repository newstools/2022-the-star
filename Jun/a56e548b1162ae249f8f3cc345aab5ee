Meta's independent system of appeals against its decisions to remove content on Facebook and Instagram had about 1.1 million cases in its first year. The disputed posts, most of which originated in the US, Canada or Europe, had largely been removed for either violence, hate speech or bullying. Of the 20 cases about which The Oversight Board published decisions, it ruled against Meta 14 times. One case was about removed images of female breasts in a breast cancer post. Others featured an image of a dead child alongside text about whether retaliation was justified against China for its treatment of Uighur Muslims, and the decision to ban Donald Trump following the Capitol Hill riots. The board overturned Meta's decision to remove the first two examples, but supported its decision to ban Mr Trump - although it criticised the "indefinite" time frame. It had initially shortlisted 130 cases to investigate, but Meta agreed up front that it had been wrong on 51 of those occasions. Board director Thomas Hughes said it looked for "emblematic" cases with "problematic elements" to take on. He added that the categories of hate speech, violence and bullying were "difficult-to-judge issues" - especially for automated systems. "Also in many of those cases, context is extremely important," he said. The board has just released its first annual report, covering the period October 2020 to December 2021. Anybody - including Meta itself - can appeal to it if they disagree with a decision to remove content. Of the 1.1 million cases received during the 14-month period, only 47 came from the firm. About 2,600 cases per day were reported on average. However, Facebook alone has more than two billion users around the world, making this a relatively tiny percentage of its vast content. It was also noticeable that relatively few complainants were from outside Western countries. Of all the cases submitted to the board: The Oversight Board is known as a kind of "supreme court" and was formed by Meta boss Mark Zuckerberg. It operates as an independent entity, although its wages and other costs are covered by Meta. It consists of journalists, human rights activists, lawyers and academics. Mr Hughes described the relationship between the board and Meta as "constructive but critical". It has made 86 additional recommendations to the tech giant, including translating its policies into more languages and being more specific when explaining why content has been removed on the grounds of hate speech.